{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# NOTE: needed for python 3.10 forward compatibility with scanpy as \n",
    "# scanpy uses Iterable which is deprecated in 3.10\n",
    "import collections.abc\n",
    "#hyper needs the four following aliases to be done manually.\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from spot_mark_gene.types import (\n",
    "    AnnData, AnnDatas, Graph, SeriesLike,\n",
    "    VAR_HUMAN_TF, VAR_MOUSE_TF,\n",
    "    VAR_HUMAN_ENSEMBLE_ID, VAR_MOUSE_ENSEMBLE_ID,\n",
    "    LAYER_PRENORM, LAYER_DETECTED,\n",
    "    LAYER_SCALED_NORMALIZED, EMB_MAGIC,\n",
    "    EMB_PCA, EMB_PCA_HVG,\n",
    "    EMB_PHATE, EMB_PHATE_HVG,\n",
    "    CUTOFF_KIND, CUTOFF_SHORTHAND_TO_OBS_KEYS,\n",
    "    CutoffSpecification, CutoffSpecifications,\n",
    "    VAR_GENE_SYMBOL, VAR_GENE_IDS,\n",
    "    OBS_DOUBLET_SCORES, OBS_PREDICTED_DOUBLETS,\n",
    "    VAR_MITO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from typing import TypeAlias, List, Sequence, Tuple\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scrublet as scr\n",
    "import scipy\n",
    "import graphtools as gt\n",
    "import phate\n",
    "import magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_gene_symbols_to_adata(adata:AnnData) -> AnnData:\n",
    "    adata.var_names_make_unique()\n",
    "    adata.var[VAR_GENE_SYMBOL] = adata.var_names\n",
    "    return adata\n",
    "\n",
    "def add_gene_ids_to_adata(adata:AnnData) -> AnnData:\n",
    "    adata.var_names = adata.var[VAR_GENE_IDS]\n",
    "    return adata\n",
    "\n",
    "def remove_mitochondrial_genes(adata:AnnData) -> AnnData:\n",
    "    adata = adata[:, ~adata.var[VAR_MITO]]\n",
    "    return adata\n",
    "\n",
    "def score_doublets(adata:AnnData, plot:bool=False) -> AnnData:   \n",
    "    scrub = scr.Scrublet(adata.X)\n",
    "    adata.obs[OBS_DOUBLET_SCORES], adata.obs[OBS_PREDICTED_DOUBLETS] =\\\n",
    "        scrub.scrub_doublets()\n",
    "    if plot:\n",
    "        scrub.plot_histogram()\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_gene_annotations(\n",
    "    adata:AnnData,\n",
    "    annotation_file:str\n",
    ") -> AnnData:\n",
    "    # Load gene annotation information (extracted from bioconductor)    \n",
    "    gene_annotation = pd.read_csv(\n",
    "        annotation_file, index_col=None, header=0\n",
    "    ).astype(str)\n",
    "\n",
    "    assert hasattr(gene_annotation, 'Ensembl')\n",
    "    gene_annotation.index = list(gene_annotation.Ensembl)\n",
    "\n",
    "    # Add to AnnData object\n",
    "    adata.var = pd.concat(\n",
    "        [adata.var, gene_annotation], axis=1, join='inner'\n",
    "    )\n",
    "    adata.var.index = list(adata.var[VAR_GENE_SYMBOL])\n",
    "    # Enforce uniqueness\n",
    "    adata.var_names_make_unique()\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from spot_mark_gene.utils import (\n",
    "    time_to_num_from_idx_to_time\n",
    ")\n",
    "def combine_timepoints(\n",
    "    *adatas:AnnDatas, \n",
    "    idx_to_time:dict,\n",
    "    print_counts:bool=False\n",
    "):\n",
    "    '''\n",
    "    Examples:\n",
    "\n",
    "        idx_to_time = {\n",
    "            '0': '12hr', \n",
    "            '1': '18hr', \n",
    "            '2': '24hr'\n",
    "        }\n",
    "\n",
    "        time_to_num = {\n",
    "            '12hr': '12', \n",
    "            '18hr': '18', \n",
    "            '24hr': '24'\n",
    "        }\n",
    "    '''\n",
    "    time_to_num = time_to_num_from_idx_to_time(idx_to_time)\n",
    "\n",
    "    adata = ad.concat(\n",
    "        [*adatas], \n",
    "        index_unique=\"_\", merge=\"same\", join='outer'\n",
    "    )\n",
    "\n",
    "    adata.obs['batch'] = adata.obs.index.astype(str).str[-1]\n",
    "\n",
    "    adata.obs['batch'] = adata.obs['batch']\\\n",
    "        .replace(idx_to_time)\n",
    "    \n",
    "    adata.obs['timepoint'] = adata.obs['batch']\\\n",
    "        .replace(time_to_num)\n",
    "\n",
    "    if print_counts:\n",
    "        print(adata.obs.batch.value_counts())\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def calc_qc_stats(adata:AnnData) -> AnnData:\n",
    "    # Calculate QC stats\n",
    "    adata.var[\"mito\"] = adata.\\\n",
    "            var_names.str.startswith(\"mt-\")\n",
    "    \n",
    "    adata.var['ribo'] = adata.\\\n",
    "            var_names.str.startswith((\"rps\",\"rpl\"))\n",
    "\n",
    "    sc.pp.calculate_qc_metrics(\n",
    "        adata, qc_vars=[\"mito\", \"ribo\"], inplace=True\n",
    "    )\n",
    "\n",
    "    adata.obs['log10_total_counts'] = np.log10(\n",
    "        adata.obs[\"total_counts\"]\n",
    "    )\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def filter_by_cutoffs(\n",
    "    adata:AnnData, \n",
    "    lower:float=None, \n",
    "    upper:float=None,\n",
    "    obs_key:CUTOFF_KIND='total_counts',\n",
    "    print_counts:bool=False,      \n",
    ") -> AnnData:\n",
    "    assert obs_key is not None\n",
    "    if lower is not None:\n",
    "        adata[adata.obs[obs_key] > lower]\n",
    "    if upper is not None:\n",
    "        adata[adata.obs[obs_key] < upper]\n",
    "    if print_counts:\n",
    "        print(adata.obs.batch.value_counts())\n",
    "    return adata\n",
    "\n",
    "def apply_filter_by_cutoffs(\n",
    "    adata:AnnData, \n",
    "    cutoff_specs:CutoffSpecifications,\n",
    "    print_counts:bool=False   \n",
    "):\n",
    "    for spec in cutoff_specs:\n",
    "        adata = filter_by_cutoffs(\n",
    "            adata, spec.lower, spec.upper, \n",
    "            spec.obs_key, print_counts\n",
    "        )\n",
    "\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_prenormalization_layer(adata:AnnData) -> AnnData:\n",
    "    # Store unnormalised counts\n",
    "    adata.layers[LAYER_PRENORM] = adata.X\n",
    "    return adata\n",
    "\n",
    "def add_gene_detection_layer(adata:AnnData) -> AnnData:\n",
    "    # Store unnormalised counts\n",
    "    if LAYER_PRENORM not in adata.layers:\n",
    "        adata = add_prenormalization_layer(adata)\n",
    "\n",
    "    # Add layer of gene detection\n",
    "    adata.layers[LAYER_DETECTED] = scipy.sparse.csr_matrix(\n",
    "        pd.DataFrame(\n",
    "        (adata.layers[LAYER_PRENORM].toarray() > 0), \n",
    "        columns = adata.var.index, index=adata.obs.index\n",
    "    ).replace({True: 1, False: 0}))\n",
    "    return adata\n",
    "\n",
    "def sqrt_library_size_normalize(adata:AnnData) -> AnnData:\n",
    "    # Normalise by library size and square-root transform\n",
    "    adata = adata.copy()\n",
    "    adata.X = scipy.sparse.csr_matrix(\n",
    "        sc.transform.sqrt(\n",
    "            sc.normalize.library_size_normalize(\n",
    "                adata.X.toarray()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def add_batch_mean_center_layer(adata:AnnData) -> AnnData:\n",
    "    # Batch mean center before cell cycle scoring\n",
    "    adata.raw = adata\n",
    "    adata.X = scipy.sparse.csr_matrix(\n",
    "        sc.normalize.batch_mean_center(\n",
    "            adata.X.toarray(), \n",
    "            sample_idx = adata.obs['batch']\n",
    "        )\n",
    "    )\n",
    "\n",
    "    adata.layers[LAYER_SCALED_NORMALIZED] = scipy.sparse.csr_matrix(adata.X)\n",
    "    adata.X = adata.raw.X\n",
    "    return adata\n",
    "\n",
    "def score_genes_cell_cycle_with_batch_mean_center_data(\n",
    "        adata:AnnData,\n",
    "        s_genes:Sequence[str], \n",
    "        g2m_genes:Sequence[str],\n",
    ") -> AnnData:\n",
    "    \n",
    "    sdata = adata.layers[LAYER_SCALED_NORMALIZED]\n",
    "    # Get normalised counts back instead of mean centered values as pca will mean center\n",
    "    sc.tl.score_genes_cell_cycle(sdata, s_genes=s_genes, g2m_genes=g2m_genes)\n",
    "    return adata\n",
    "\n",
    "def load_human_genes(\n",
    "    adata:AnnData, filename:str\n",
    ") -> List[str]:\n",
    "    '''\n",
    "    NOTE:\n",
    "        - uses adata to confirm validity\n",
    "    '''\n",
    "    assert hasattr(adata.var, 'HumanGeneSymbol')\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        genes = f.readlines()\n",
    "        genes = [gene.strip() for gene in genes]\n",
    "        genes = adata.var.index[adata.var.HumanGeneSymbol.isin(genes)]\n",
    "        return genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def select_hvg_per_batch(\n",
    "    adata:AnnData,\n",
    "    hvg_kwargs:dict=dict(cutoff=None, percentile=90)\n",
    ") -> AnnData:\n",
    "    # Select highly variable genes from any batch\n",
    "    hvg_all = []\n",
    "    for batch in adata.obs.batch.unique():\n",
    "        normalised, hgv_vars = sc.select.highly_variable_genes(\n",
    "            adata[adata.obs.batch == batch].X.toarray(), \n",
    "            adata[adata.obs.batch == batch].var.index, \n",
    "            **hvg_kwargs\n",
    "        )\n",
    "        hvg_all.extend(hgv_vars)\n",
    "        adata.var[f'highly_variable_{batch}'] = adata.var.index.isin(hgv_vars)\n",
    "        del normalised\n",
    "        print(f\"Unique HVGs after {batch} {len(np.unique(np.array(hvg_all)))}\")\n",
    "        \n",
    "    adata.var['highly_variable'] = adata.var.index.isin(hvg_all)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def add_tf_annotations_from_csv(\n",
    "    adata:AnnData, filename:str,\n",
    "    tf_key:str, ensemble_key:str,\n",
    "    print_counts:bool=False\n",
    ") -> AnnData:\n",
    "    assert hasattr(adata.var, ensemble_key)\n",
    "    df_tfs = pd.read_csv(filename, index_col=None, header=0).astype(str)\n",
    "    \n",
    "    adata.var[tf_key] = adata.var[ensemble_key]\\\n",
    "        .isin(df_tfs[ensemble_key])\n",
    "\n",
    "    if print_counts:\n",
    "        print(adata.var[tf_key].value_counts())\n",
    "    return adata\n",
    "\n",
    "def add_human_tfs_from_csv(\n",
    "    adata:AnnData, filename:str,\n",
    "    print_counts:bool=False\n",
    ") -> AnnData:\n",
    "    return add_tf_annotations_from_csv(\n",
    "        adata, filename, VAR_HUMAN_TF,\n",
    "        VAR_HUMAN_ENSEMBLE_ID, print_counts\n",
    "    )\n",
    "\n",
    "def add_mouse_tfs_from_csv(\n",
    "    adata:AnnData, filename:str,\n",
    "    print_counts:bool=False\n",
    ") -> AnnData:    \n",
    "    return add_tf_annotations_from_csv(\n",
    "        adata, filename, VAR_MOUSE_TF,\n",
    "        VAR_MOUSE_ENSEMBLE_ID, print_counts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from scipy.stats import zscore\n",
    "def zscore_markers_in_layer(\n",
    "    adata:AnnData,\n",
    "    markers:List[str],\n",
    "    obs_key:str='Markers_zscore',\n",
    "    layer_key:str=EMB_MAGIC,    \n",
    ") -> AnnData:    \n",
    "    # Score cells based on select marker expression (sum of zscores of smoothed counts)\n",
    "    col_subset = adata.var.index.isin(markers)\n",
    "    df_markers = pd.DataFrame(\n",
    "        adata.layers[layer_key][:, col_subset].toarray(), \n",
    "        columns = adata.var.index[col_subset],\n",
    "        index = adata.obs.index\n",
    "    )\n",
    "    df_markers.apply(zscore)\n",
    "    adata.obs[obs_key] = df_markers.sum(axis=1)\n",
    "    return adata\n",
    "\n",
    "def subset_markers(\n",
    "    adata:AnnData,\n",
    "    obs_key:str='Markers_cell',\n",
    "    score_key:str='Markers_zscore',\n",
    "    lower:float=2.2,\n",
    "    upper:float=None,\n",
    "    marker_name:str='marker',\n",
    "    other_name:str='other'\n",
    ") -> AnnData:\n",
    "    u_cut = pd.Series([True for t in adata.obs])\n",
    "    l_cut = pd.Series([True for t in adata.obs])\n",
    "    if upper is not None:\n",
    "        u_cut = (adata.obs[score_key] < upper)\n",
    "\n",
    "    if lower is not None:\n",
    "        l_cut = (lower < adata.obs[score_key])\n",
    "\n",
    "    adata.obs[obs_key] = (u_cut & l_cut).replace({True: marker_name, False: other_name})\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_pca(\n",
    "    adata:AnnData,\n",
    "    pca_kwargs:dict=dict(n_components=100),\n",
    "    plot_scree:bool=False,\n",
    "    emb_key:str=EMB_PCA,\n",
    "    col_subset:SeriesLike=None\n",
    ") -> AnnData:\n",
    "    # Compute PCs for initial cell graph\n",
    "    pca_kwargs['return_singular_values'] = True\n",
    "    pca_kwargs['seed'] = 3\n",
    "\n",
    "    if col_subset is not None:\n",
    "        x = adata[:, col_subset].X.toarray()\n",
    "    else:\n",
    "        x = adata.X.toarray()\n",
    "\n",
    "    pcs, svs = sc.reduce.pca(x, **pca_kwargs)\n",
    "    adata.obsm[emb_key] = pcs\n",
    "    if plot_scree:\n",
    "        sc.plot.scree_plot(svs, cumulative=False)\n",
    "    return adata\n",
    "\n",
    "def run_pca_on_hvg(\n",
    "    adata:AnnData,\n",
    "    pca_kwargs:dict=dict(n_components=100),\n",
    "    plot_scree:bool=False,\n",
    ") -> AnnData:\n",
    "    return run_pca(\n",
    "        adata, pca_kwargs, plot_scree,\n",
    "        EMB_PCA_HVG, adata.var.highly_variable\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def run_phate_using_g(\n",
    "    adata:AnnData,    \n",
    "    g: Graph = None,\n",
    "    phate_kwargs:dict = dict(t=70),\n",
    "    g_kwargs:dict = dict(knn=10),    \n",
    "    emb_key:str=EMB_PHATE, \n",
    ") -> Tuple[AnnData, Graph]:  \n",
    "    # Make initial cellwise graph with HVGS (auto t=46)\n",
    "    g_kwargs['random_state'] = 3\n",
    "    g_kwargs['n_pca'] = None\n",
    "    phate_kwargs['random_state'] = 3 \n",
    "\n",
    "    if g is None:        \n",
    "        pca_key = emb_key.replace('phate', 'pca')        \n",
    "        print((\n",
    "            f'g is None. Will attempt to calculate with'\n",
    "            f' PCA stored in adata.obsm{pca_key}.'\n",
    "        ))\n",
    "\n",
    "        if pca_key not in adata.obsm:\n",
    "            raise ValueError(f'{pca_key} not in adata.obsm')\n",
    "        \n",
    "        g = gt.Graph(\n",
    "            adata.obsm[pca_key], n_pca=None, \n",
    "            **g_kwargs\n",
    "        )\n",
    "\n",
    "    phate_op = phate.PHATE(**phate_kwargs)\n",
    "    data_phate = phate_op.fit_transform(g)\n",
    "    adata.obsm[emb_key] = data_phate\n",
    "    return adata, g\n",
    "\n",
    "def run_phate_on_hvg(\n",
    "    adata:AnnData,    \n",
    "    g: Graph = None,\n",
    "    phate_kwargs:dict = dict(t=70),\n",
    "    g_kwargs:dict = dict(knn=10),    \n",
    "    emb_key:str=EMB_PHATE_HVG,    \n",
    ") -> Tuple[AnnData, Graph]:\n",
    "    return run_phate_using_g(\n",
    "        adata, g, phate_kwargs, g_kwargs, emb_key\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_magic(\n",
    "    adata:AnnData, g:Graph,\n",
    "    knn_max:int = 60\n",
    ") -> AnnData:\n",
    "    G = copy.deepcopy(g)\n",
    "    G.knn_max = knn_max\n",
    "    G.data = adata.to_df()\n",
    "    G.data_nu = adata.to_df()\n",
    "    magic_op = magic.MAGIC().fit(adata.to_df(), graph=G)\n",
    "    data_magic = magic_op.transform(genes='all_genes')\n",
    "    adata.layers['X_magic'] = scipy.sparse.csr_matrix(data_magic)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
