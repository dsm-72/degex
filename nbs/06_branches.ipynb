{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Branches\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# NOTE: needed for python 3.10 forward compatibility with scanpy as \n",
    "# scanpy uses Iterable which is deprecated in 3.10\n",
    "import collections.abc\n",
    "#hyper needs the four following aliases to be done manually.\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "collections.Mapping = collections.abc.Mapping\n",
    "collections.MutableSet = collections.abc.MutableSet\n",
    "collections.MutableMapping = collections.abc.MutableMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import graphtools\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import scprep, scipy as sp, phate\n",
    "\n",
    "class BranchPointPredictor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(\n",
    "        self, \n",
    "        phate_op: phate.PHATE, # a trained PHATE operator\n",
    "        extrema_percentile:float = 50, # percentile to mask when calculating extrema\n",
    "        diffusion_iterations:int=20 # number of iterations to diffuse\n",
    "    ):\n",
    "        \n",
    "        self.phate_op = phate_op\n",
    "        self.extrema_percentile = extrema_percentile\n",
    "        self.diffusion_iterations = diffusion_iterations\n",
    "                      \n",
    "    def fit(self, X, y=None):\n",
    "        self.diffuse_dirac_for_end_points()\n",
    "        self.assign_branches(X)\n",
    "        self.plot_branchs(X)\n",
    "        self.plot_branch_classes(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.classes\n",
    "    \n",
    "\n",
    "    # NOTE: these two properties are for convenience of the developer\n",
    "    # and they just expose the underlying PHATE operator values\n",
    "    @property\n",
    "    def diff_op(self):\n",
    "        try:\n",
    "            return self.phate_op.diff_op\n",
    "        except AttributeError:\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def optimal_t(self):\n",
    "        try:\n",
    "            return self.phate_op.optimal_t\n",
    "        except AttributeError:\n",
    "            return None\n",
    "    \n",
    "\n",
    "    # NOTE: listing all properties up top for readability\n",
    "    @property\n",
    "    def dmap(self):\n",
    "        '''\n",
    "        Returns the diffusion map calculated from the diffusion operator\n",
    "        '''\n",
    "        try:\n",
    "            return self._dmap\n",
    "        except AttributeError:        \n",
    "            self._calc_dmap()            \n",
    "            return self._dmap \n",
    "\n",
    "    @property\n",
    "    def n_use(self):\n",
    "        '''\n",
    "        The number of eigenvectors in the diffusion map to use\n",
    "        for downstream analyses\n",
    "        '''\n",
    "        try:\n",
    "            return self._n_use\n",
    "        except AttributeError:        \n",
    "            self._calc_num_to_consider()            \n",
    "            return self._n_use \n",
    "\n",
    "    @property\n",
    "    def most_distinct_points(self):\n",
    "        '''\n",
    "        The most distinct points **prior** to downstream analysis.\n",
    "        These are the extrema.\n",
    "        '''\n",
    "        try:\n",
    "            return self._most_distinct_points\n",
    "        except AttributeError:        \n",
    "            self._calc_extrema()          \n",
    "            return self._most_distinct_points\n",
    "       \n",
    "    @property\n",
    "    def is_landmarked(self):\n",
    "        '''\n",
    "        Whether or not the graph in the PHATE operator is a Landmark Graph\n",
    "        which matters when reconstructing class labels\n",
    "        '''\n",
    "        return isinstance(self.phate_op.graph, graphtools.graphs.kNNLandmarkGraph)\n",
    "    \n",
    "    # NOTE: these two properties are for handling reconstruction from the landmark operator\n",
    "    # back to the original data space.\n",
    "    @property\n",
    "    def pmn(self):\n",
    "        try:\n",
    "            return self.phate_op.graph.transitions\n",
    "        except Exception:        \n",
    "            return None\n",
    "        \n",
    "    @property\n",
    "    def pnm(self):\n",
    "        try:\n",
    "            return self.phate_op.graph._data_transitions()\n",
    "        except Exception:        \n",
    "            return None\n",
    "        \n",
    "    @property\n",
    "    def n_rows(self):\n",
    "        return self.pmn.shape[0] if self.pmn is not None else self.diff_op.shape[0]\n",
    "    \n",
    "    @property\n",
    "    def nn_dist(self):\n",
    "        '''\n",
    "        Nearest Neighbor distance matrix calculated on diffusion operator\n",
    "        '''\n",
    "        try:\n",
    "            return self._nn_dist\n",
    "        except AttributeError:\n",
    "            self._knn_on_diff_op()\n",
    "            return self._nn_dist\n",
    "        \n",
    "    @property\n",
    "    def nn_idxs(self):\n",
    "        '''\n",
    "        Nearest Neighbor indicies calculated on diffusion operator\n",
    "        '''\n",
    "        try:\n",
    "            return self._nn_idxs\n",
    "        except AttributeError:\n",
    "            self._knn_on_diff_op()\n",
    "            return self._nn_idxs\n",
    "        \n",
    "    @property\n",
    "    def n_nbrs(self):\n",
    "        try:\n",
    "            return self._n_nbrs\n",
    "        except AttributeError:\n",
    "            self.max_likelihood_pointwise_dimensionality_est()\n",
    "            return self._n_nbrs\n",
    "    \n",
    "    @property\n",
    "    def nbrs_dim_est(self):\n",
    "        try:\n",
    "            return self._nbrs_dim_est\n",
    "        except AttributeError:\n",
    "            self.max_likelihood_pointwise_dimensionality_est()\n",
    "            return self._nbrs_dim_est\n",
    "    \n",
    "    @property\n",
    "    def most_distinct_points_adjusted(self):\n",
    "        try:\n",
    "            return self._most_distinct_points_adjusted\n",
    "        except AttributeError:\n",
    "            self.max_likelihood_pointwise_dimensionality_est()\n",
    "            return self._most_distinct_points_adjusted\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        '''\n",
    "        Branch class labels\n",
    "        '''\n",
    "        try:\n",
    "            return self._classes\n",
    "        except AttributeError:\n",
    "            self.diffuse_dirac_for_end_points()\n",
    "            return self._classes\n",
    "        \n",
    "    @property\n",
    "    def branch_classes(self):\n",
    "        try:\n",
    "            return self._branch_classes\n",
    "        except AttributeError:\n",
    "            self.assign_branches(self.phate_op.X)\n",
    "            return self._branch_classes\n",
    "\n",
    "    @property\n",
    "    def branch_points(self):\n",
    "        try:\n",
    "            return self._branch_points\n",
    "        except AttributeError:\n",
    "            self.diffuse_dirac_for_end_points()\n",
    "            return self._branch_points\n",
    "    \n",
    "    # NOTE: sets property dmap\n",
    "    def _calc_dmap(self, t=None):\n",
    "        if t is None:\n",
    "            t = self.optimal_t\n",
    "\n",
    "        evals, evecs = np.linalg.eig(self.diff_op)\n",
    "                \n",
    "        # sort eigenvectors in descending order\n",
    "        idx = np.abs(evals).argsort()[::-1]\n",
    "        evals = evals[idx]\n",
    "        evecs = evecs[:, idx]\n",
    "\n",
    "        # do diffusion        \n",
    "        evals = np.power(evals, self.optimal_t)\n",
    "        evecs = evecs.dot(np.diag(evals))\n",
    "\n",
    "        self.evals = evals\n",
    "        self.evecs = evecs\n",
    "        self._dmap = evecs   \n",
    "        return evecs\n",
    "\n",
    "    # NOTE: sets property n_use      \n",
    "    def _calc_num_to_consider(self):\n",
    "        dmap = self.dmap\n",
    "        evals = self.evals\n",
    "        \n",
    "        # Number of eigenvectors (~ dimensions) to consider.\n",
    "        dmap_diff = evals - np.roll(evals, 1)\n",
    "        \n",
    "        n_evecs = 1\n",
    "        # Increase the number of eigenvectors until \n",
    "        while (dmap_diff[n_evecs + 1] > 2 * dmap_diff[n_evecs]):\n",
    "            n_evecs += 1\n",
    "        \n",
    "        self._n_use = n_evecs\n",
    "        return n_evecs\n",
    "    \n",
    "    # NOTE: sets property most_distinct_points\n",
    "    def _calc_extrema(self):\n",
    "        # NOTE: these functions are equivalent, but\n",
    "        # v2 is used in latest version on GitHub and\n",
    "        # although v1 looks cleaner\n",
    "        return self.__calc_extrema_v2()\n",
    "        return self.__calc_extrema_v1()\n",
    "    \n",
    "    def __calc_extrema_v1(self):\n",
    "        dmap = self.dmap\n",
    "\n",
    "        # Ignore first (trivial) eigenvector\n",
    "        dmap = dmap[:, 1:].copy()\n",
    "\n",
    "        # Mask lower 50% abs val\n",
    "        lower_half_abs = np.percentile(np.abs(dmap), self.extrema_percentile)\n",
    "        dmap[np.abs(dmap) < lower_half_abs] = 0\n",
    "\n",
    "        max_idxs = dmap.argmax(axis=0)\n",
    "        min_idxs = dmap.argmin(axis=0)\n",
    "        extrema_idxs = np.unique(np.hstack((max_idxs, min_idxs)))\n",
    "        self._most_distinct_points = extrema_idxs\n",
    "        return extrema_idxs\n",
    "\n",
    "    def __calc_extrema_v2(self):\n",
    "        # Find the extremas (min and max) of the considered eigenvectors.\n",
    "        # Keep them in the order of the eigenvalues by weaving min and max values.\n",
    "        # min_eigs = phate_op_eigvecs[:,1:n_eigvecs+1].argmin(0)\n",
    "        # max_eigs = phate_op_eigvecs[:,1:n_eigvecs+1].argmax(0)\n",
    "        # combined_eigs = np.empty((min_eigs.size + max_eigs.size,), dtype=min_eigs.dtype)\n",
    "        # combined_eigs[0::2] = min_eigs\n",
    "        # combined_eigs[1::2] = max_eigs\n",
    "\n",
    "        # Remove duplicates.\n",
    "\n",
    "        # for e in combined_eigs:\n",
    "        #     if e not in most_distinct_points:\n",
    "        #         most_distinct_points.append(e)\n",
    "\n",
    "        n_consider = self.n_use\n",
    "        dmap = self.dmap\n",
    "\n",
    "        most_distinct_points = []\n",
    "\n",
    "        # Always skip the first trivial eigenvector\n",
    "        for i in np.arange(n_consider):\n",
    "            cur_eigvec = np.copy(dmap[:,i+1])\n",
    "            # Sometimes the eigvectors are skewed towards one side (much more possitive values than negative \n",
    "            # values and vice versa). This part ensures only the extrema on the more significant side is taken.            \n",
    "            lower_half_abs = np.percentile(np.abs(cur_eigvec), self.extrema_percentile)\n",
    "            cur_eigvec[np.abs(cur_eigvec) < lower_half_abs] = 0\n",
    "\n",
    "            max_eig = np.argmax(cur_eigvec)\n",
    "            min_eig = np.argmin(cur_eigvec)\n",
    "\n",
    "            if cur_eigvec[max_eig] > 0 and max_eig not in most_distinct_points:\n",
    "                most_distinct_points.append(max_eig)\n",
    "            \n",
    "            if cur_eigvec[min_eig] < 0 and min_eig not in most_distinct_points:\n",
    "                most_distinct_points.append(min_eig)\n",
    "\n",
    "        most_distinct_points = np.array(most_distinct_points)\n",
    "        self._most_distinct_points = most_distinct_points\n",
    "        return most_distinct_points        \n",
    "\n",
    "        \n",
    "    def _knn_on_diff_op(self):\n",
    "        # NOTE: using KNN on diff_map is not invertable\n",
    "        # i.e. need to revert landmark graph here!\n",
    "        dmap = self.dmap\n",
    "\n",
    "        #######################\n",
    "        # INTRINSIC DIMENSION #\n",
    "        #######################\n",
    "\n",
    "        # Based on maxLikPointwiseDimEst() of this R package.\n",
    "        # https://cran.r-project.org/web/packages/intrinsicDimension/README.html\n",
    "\n",
    "        # Up to 100 dimensions of diffusion maps, \n",
    "        # raised to the same power as tdetermined by PHATE.\n",
    "        dm_dims = min(self.diff_op.shape[1], 100) # NOTE: oroginaly was data.shape[1]\n",
    "        diff_map = dmap[:,:dm_dims]\n",
    "        # diff_map = diff_map.dot(np.diag(np.power(phate_op_eigvals[:dm_dims], 11)))\n",
    "        if self.is_landmarked:\n",
    "            diff_map = self.phate_op.graph.interpolate(diff_map)\n",
    "    \n",
    "        # Rank all neighbors in diffusion map coordinates.\n",
    "        nbrs = NearestNeighbors(\n",
    "            # n_neighbors=dm_dims,\n",
    "            n_neighbors=diff_map.shape[0],\n",
    "            algorithm='ball_tree'\n",
    "        ).fit(diff_map)\n",
    "\n",
    "        nn_distances, nn_indices = nbrs.kneighbors(diff_map)\n",
    "        nn_distances = nn_distances[:, 1:]\n",
    "        nn_indices = nn_indices[:, 1:]\n",
    "        self._nn_dist = nn_distances\n",
    "        self._nn_idxs = nn_indices\n",
    "        return nn_distances, nn_indices\n",
    "\n",
    "    def max_likelihood_pointwise_dimensionality_est(self):\n",
    "        n_rows = self.n_rows\n",
    "        nn_dist = self.nn_dist\n",
    "        nn_idxs = self.nn_idxs \n",
    "        most_distinct_points = np.copy(self.most_distinct_points)\n",
    "\n",
    "        # Maximum Likelihood pointwise dimensionality estimation\n",
    "        # Hill (1975), Levina and Bickel (2005)\n",
    "        row_max = np.max(nn_dist, axis=1)\n",
    "        row_max = row_max.reshape(len(row_max), 1)\n",
    "        dim_est = np.sum(np.log(row_max / nn_dist), axis=1)\n",
    "\n",
    "        # Calculate the average dim_est of local neighborhood.\n",
    "        n_nbrs = min(n_rows // 20, 100)\n",
    "        nbrs_dim_est = np.average(dim_est[nn_idxs[:, :n_nbrs]], axis=1)\n",
    "        # nbrs_dim_est = phate_op.graph.interpolate(nbrs_dim_est)\n",
    "\n",
    "        # Calculate ranking of neighborhood dim_est, from low to high\n",
    "        temp = nbrs_dim_est.argsort()\n",
    "        nbrs_dim_est_ranks = np.empty_like(temp)\n",
    "        nbrs_dim_est_ranks[temp] = np.arange(len(nbrs_dim_est))\n",
    "\n",
    "        # Make sure that all distinct points are end points (low dim_est), \n",
    "        # not branch point (high dim_est)\n",
    "        low_dim_est_mask = nbrs_dim_est_ranks[most_distinct_points] < n_rows // 2\n",
    "        most_distinct_points = most_distinct_points[low_dim_est_mask]\n",
    "\n",
    "        self._most_distinct_points_adjusted = most_distinct_points\n",
    "        self._n_nbrs = n_nbrs\n",
    "        self._nbrs_dim_est = nbrs_dim_est\n",
    "        return n_nbrs, nbrs_dim_est\n",
    "    \n",
    "    def diffuse_dirac_for_end_points(self):        \n",
    "        n_nbrs = self.n_nbrs        \n",
    "        nbrs_dim_est = self.nbrs_dim_est\n",
    "        # NOTE: use adjusted distinct points from max_likelihood_pointwise_dimensionality_est\n",
    "        most_distinct_points = self.most_distinct_points_adjusted\n",
    "\n",
    "        ##################################\n",
    "        # DIFFUSING DIRAC FOR END POINTS #\n",
    "        ##################################\n",
    "        pnm = self.pnm\n",
    "        pmn = self.pmn\n",
    "        opt_t = self.optimal_t\n",
    "        nn_idxs = self.nn_idxs        \n",
    "        n_rows = self.n_rows\n",
    "\n",
    "        branch_points = []\n",
    "        classes = np.zeros(n_rows, dtype=\"int32\") # NOTE: original was data\n",
    "        classes_value = np.repeat(-float('inf'), n_rows)\n",
    "        for end_point_index in np.arange(most_distinct_points.size):\n",
    "            cur_end_point = most_distinct_points[end_point_index]\n",
    "                        \n",
    "            if self.is_landmarked:\n",
    "                undo_diff = (pmn @ self.diff_op @ pnm)\n",
    "                diff_op_t = np.linalg.matrix_power(undo_diff, opt_t)\n",
    "            else:\n",
    "                diff_op_t = np.linalg.matrix_power(self.diff_op, opt_t)            \n",
    "\n",
    "            branch_point_dim_est_avg_cache = -float('inf')\n",
    "\n",
    "            for it in range(self.diffusion_iterations):\n",
    "                branch_from_end_point = diff_op_t[:, cur_end_point]\n",
    "\n",
    "                branch_max = np.max(branch_from_end_point)\n",
    "                branch_min = np.min(branch_from_end_point)\n",
    "                \n",
    "                branch_threshold = branch_min + (branch_max - branch_min) * 0.1\n",
    "                \n",
    "                deviation_from_branch_threshold = branch_from_end_point - branch_threshold\n",
    "                deviation_from_branch_threshold[deviation_from_branch_threshold < 0] = float('inf')\n",
    "\n",
    "                cur_branch_point = deviation_from_branch_threshold.argmin()\n",
    "                potential_branch_points = np.argpartition(deviation_from_branch_threshold, 20)[:20]\n",
    "                \n",
    "                branch_point_dim_est_avg = np.average(nbrs_dim_est[potential_branch_points])\n",
    "                if (branch_point_dim_est_avg < branch_point_dim_est_avg_cache):\n",
    "                    break\n",
    "                branch_point_dim_est_avg_cache = branch_point_dim_est_avg\n",
    "                                \n",
    "                if self.is_landmarked:                                \n",
    "                    undo_diff = (pmn @ self.diff_op @ pnm)\n",
    "                    diff_op_t = diff_op_t.dot(undo_diff)\n",
    "                else:\n",
    "                    diff_op_t = diff_op_t.dot(self.diff_op)\n",
    "\n",
    "            branch_points.append(cur_branch_point)\n",
    "            on_branch_mask = diff_op_t[:, cur_end_point] > branch_threshold\n",
    "            color = diff_op_t[:, cur_end_point]\n",
    "\n",
    "            on_branch_mask[color < classes_value] = 0\n",
    "\n",
    "            color[np.logical_not(on_branch_mask)] = -np.max(color)\n",
    "\n",
    "            classes_value[on_branch_mask] = color[on_branch_mask]\n",
    "            classes[on_branch_mask] = end_point_index + 1\n",
    "\n",
    "        #####################\n",
    "        # REMOVE DUPLICATES #\n",
    "        #####################\n",
    "        # We want to remove branch points that are too close together.\n",
    "        branch_points = np.array(branch_points)\n",
    "        branch_point_nbrs = nn_idxs[branch_points, :n_nbrs]\n",
    "        branch_point_pairs_mask = np.isin(branch_point_nbrs, branch_points)\n",
    "        center_branch_point = branch_points[np.where(branch_point_pairs_mask)[0]]\n",
    "        neighbor_branch_point = branch_point_nbrs[branch_point_pairs_mask]\n",
    "        branch_point_pairs = list(zip(center_branch_point, neighbor_branch_point))\n",
    "\n",
    "        # For each pair of branch_points, keep only the one with higher eigenvalue.\n",
    "        # (mdb_pairs, by construction, is sorted by decreasing eigenvalue corresponding \n",
    "        # to the first point of each pair.)\n",
    "        points_to_exclude = []\n",
    "        for pair in branch_point_pairs:\n",
    "            if pair[0] not in points_to_exclude:\n",
    "                points_to_exclude.append(pair[1])\n",
    "\n",
    "        branch_points = np.delete(\n",
    "            branch_points, \n",
    "            np.argwhere(np.isin(branch_points, points_to_exclude))\n",
    "        )\n",
    "        self._classes = classes\n",
    "        self._branch_points = branch_points\n",
    "        return branch_points\n",
    "\n",
    "    def assign_branches(self, emb):\n",
    "        ###################\n",
    "        # ASSIGN BRANCHES #\n",
    "        ###################\n",
    "        dmap = self.dmap\n",
    "        most_distinct_points = self.most_distinct_points_adjusted\n",
    "\n",
    "        # Find coordinates between every point and every MDP.\n",
    "        all_dm_coords = dmap\n",
    "        if self.is_landmarked:\n",
    "            all_dm_coords = (self.pmn @ self.dmap @ self.pnm)\n",
    "        mdp_dm_coords = all_dm_coords[most_distinct_points,:]\n",
    "        pairwise_dist = sp.spatial.distance.cdist(all_dm_coords, mdp_dm_coords)\n",
    "\n",
    "        # For every point, rank MDPs by increasing distance.\n",
    "        s = np.argsort(pairwise_dist, axis=1)\n",
    "        i = np.arange(pairwise_dist.shape[0]).reshape(-1, 1)\n",
    "        j = np.arange(pairwise_dist.shape[1])\n",
    "        \n",
    "        mdp_ranking = np.empty_like(pairwise_dist, dtype=int)\n",
    "        mdp_ranking[i, s] = j + 1\n",
    "\n",
    "        # Assign every point to the branch between its two most highly ranked MDPs.\n",
    "        mdp_1 = np.argwhere(mdp_ranking==1)[:,1] + 1\n",
    "        mdp_2 = np.argwhere(mdp_ranking==2)[:,1] + 1\n",
    "        \n",
    "        branch_classes = list(zip(mdp_1, mdp_2))\n",
    "        branch_classes = [str(sorted(branch_class)) for branch_class in branch_classes]\n",
    "        self._branch_classes = branch_classes \n",
    "\n",
    "    def plot_branchs(self, emb):\n",
    "        most_distinct_points = self.most_distinct_points_adjusted\n",
    "        branch_points = self.branch_points\n",
    "        # Plot by class with end points and branch points\n",
    "        classes = self.classes        \n",
    "        ax = scprep.plot.scatter2d(emb, c=classes)\n",
    "        plot_numbers = np.repeat(\"\", emb.shape[0])\n",
    "        plot_numbers[most_distinct_points] = np.arange(most_distinct_points.shape[0]) + 1\n",
    "        plot_numbers[branch_points] = \"*\"\n",
    "        bbox_props = dict(boxstyle=\"circle,pad=0.3\", fc=\"w\", ec=\"r\", lw=2)\n",
    "        \n",
    "        for i, txt in enumerate(plot_numbers):\n",
    "            ax.annotate(txt, (emb[i][0], emb[i][1]), size=15, bbox=bbox_props)\n",
    "\n",
    "    def plot_branch_classes(self, emb):\n",
    "        branch_classes = self.branch_classes\n",
    "        most_distinct_points = self.most_distinct_points_adjusted\n",
    "\n",
    "        ax = scprep.plot.scatter2d(emb, c=branch_classes)\n",
    "        \n",
    "        plot_numbers = np.repeat(\"\", emb.shape[0])\n",
    "        plot_numbers[most_distinct_points] = np.arange(most_distinct_points.shape[0]) + 1\n",
    "        bbox_props = dict(boxstyle=\"circle,pad=0.3\", fc=\"w\", ec=\"r\", lw=2)\n",
    "\n",
    "        # sys.stdout = open('trash', 'w')\n",
    "        for i, txt in enumerate(plot_numbers):\n",
    "            ax.annotate(txt, (emb[i][0], emb[i][1]), size=15, bbox=bbox_props)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def hacky_branch_point_prediction(\n",
    "    emb,\n",
    "    nearest_n=200,\n",
    "    farest_n=5,    \n",
    "    percentile=99,\n",
    "    nearby_filter=None,\n",
    "    clusters=None,\n",
    "    toggle=True\n",
    "):\n",
    "    # pairwise distances in embedding space\n",
    "    dist_mat = sp.spatial.distance.cdist(emb, emb)\n",
    "\n",
    "    max_perc = 100\n",
    "    cur_perc = max_perc - percentile\n",
    "\n",
    "    # row is point we are looking at, cols are indicies of __furtherst__ neighbors first\n",
    "    neigh_dist_sorted = dist_mat.argsort(axis=1)\n",
    "    \n",
    "    # row is point we are looking at, cols are indicies of __closest__ neighbors first\n",
    "    neigh_dist_sorted = neigh_dist_sorted[:, ::-1]    \n",
    "    if toggle:\n",
    "        # NOTE: toggle = False --> farest (farest_n) of closest (nearest_n) neighbors\n",
    "        # NOTE: toggle = True --> closest (farest_n) of farest (nearest_n) neighbors\n",
    "        # we go back to taking the closest of the furthest data\n",
    "        neigh_dist_sorted = neigh_dist_sorted[:, ::-1]    \n",
    "    \n",
    "    # n nearest neighbors\n",
    "    near = neigh_dist_sorted[:, :nearest_n]\n",
    "    \n",
    "    # n nearest sorted to be furthest first\n",
    "    near = near[:, ::-1]\n",
    "    # n farest\n",
    "    far = near[:, :farest_n]\n",
    "\n",
    "    dist_mat_of_farest_nearby = dist_mat.take(far[far])\n",
    "    mean_dist_of_farest_nearby = dist_mat_of_farest_nearby.mean(axis=1)\n",
    "    stds = np.std(mean_dist_of_farest_nearby, axis=1)\n",
    "\n",
    "    where_above = stds > np.percentile(stds, percentile)\n",
    "\n",
    "    branch_point_guesses = np.where(where_above == True)[0]\n",
    "    if nearby_filter is not None:\n",
    "        keep = []\n",
    "        ignore = []\n",
    "        for ip, pnt in enumerate(branch_point_guesses):\n",
    "            for ont in branch_point_guesses[ip+1:]:      \n",
    "                \n",
    "                if dist_mat[pnt, ont] < nearby_filter:\n",
    "                    ignore.append(ont)\n",
    "                    continue        \n",
    "                    \n",
    "                if pnt in keep:\n",
    "                    continue\n",
    "                if pnt in ignore:\n",
    "                    continue\n",
    "                keep.append(pnt)\n",
    "        branch_point_guesses = keep\n",
    "\n",
    "\n",
    "    if clusters is None:\n",
    "        clusters = ['unknown' for e in emb]\n",
    "    \n",
    "    ax = scprep.plot.scatter2d(emb, c=clusters)    \n",
    "    for i, node in enumerate(branch_point_guesses):\n",
    "        coord = branch_point_guesses[i]\n",
    "        ax.annotate(node, (emb[coord][0], emb[coord][1]), size=15)\n",
    "    return branch_point_guesses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
